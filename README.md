# Mini ML Platform

Este projeto simula uma plataforma simplificada de deploy de modelos de Machine Learning, composta por:

- Treinamento automatizado de um modelo
- Servimento via API REST documentada com Swagger
- ContainerizaÃ§Ã£o com Docker e Docker Compose

A API estÃ¡ preparada para consumir modelos treinados localmente. Neste exemplo, Ã© utilizado o dataset Iris e um classificador RandomForestClassifier.

## Estrutura do Projeto

mini-ml-platform/
â”œâ”€â”€ train/              # CÃ³digo para treinar o modelo
â”‚   â””â”€â”€ train.py
â”œâ”€â”€ serve/              # API REST com FastAPI
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ init.py
â”‚   â””â”€â”€ model.pkl       # Modelo salvo apÃ³s o treinamento
â”œâ”€â”€ tests/              # Testes automatizados com pytest
â”‚   â””â”€â”€ test_api.py
â”œâ”€â”€ Dockerfile          # Imagem Docker da aplicaÃ§Ã£o
â”œâ”€â”€ docker-compose.yml  # OrquestraÃ§Ã£o dos containers
â”œâ”€â”€ requirements.txt    # Lista de dependÃªncias
â””â”€â”€ README.md           # InstruÃ§Ãµes e informaÃ§Ãµes do projeto

## O que o cÃ³digo faz

1. `train/train.py`: treina um modelo RandomForest usando o dataset Iris e salva como serve/model.pkl.
2. `serve/app.py`: implementa uma API REST com FastAPI que carrega o modelo treinado e expÃµe o endpoint /predict.
3. `Dockerfile` e `docker-compose.yml`: permitem executar treinamento, API e testes automatizados em containers isolados.
4. O modelo Ã© acessado dentro de um container Docker e exposto localmente via porta `8000`.


## InstruÃ§Ãµes para rodar localmente

### Clonar o repositÃ³rio

```bash
git clone <url-do-repositorio>
cd mini-ml-platform
```

### Criar e ativar o ambiente virtual
## VersÃ£o utilizada do Python para esse cÃ³digo foi Python 3.12.10

```bash
python -m venv venv
source venv/bin/activate     # Linux/macOS
.\venv\Scripts\activate    # Windows
```

### Instalar as dependÃªncias - versÃ£o utilizada do Python 3.12.10 para esse exercicio

```bash
pip install --upgrade pip setuptools wheel
pip install -r requirements.txt
```

## Treinar o modelo

Para treinar o modelo dentro de um container Docker e gerar o arquivo `serve/model.pkl`, execute:

```bash
docker-compose run --rm train
```
ðŸ’¡ Nota: Caso deseje adaptar a plataforma para outros modelos e dados, basta alterar o conteÃºdo do script train/train.py, treinando o modelo desejado e salvando como serve/model.pkl. A API irÃ¡ carregÃ¡-lo automaticamente no momento da inicializaÃ§Ã£o.

## Subir a API com Docker Compose

ApÃ³s o treinamento, inicie os containers:

```bash
docker-compose up --build
```

## Acessar a documentaÃ§Ã£o Swagger

Abra no navegador: http://localhost:8000/docs

## Como testar a API no Swagger

1. Clique no endpoint `POST /predict`
2. Clique no botÃ£o "Try it out"
3. Insira o seguinte corpo de requisiÃ§Ã£o:

```json
{
  "features": [5.1, 3.5, 1.4, 0.2]
}
```

4. Clique em "Execute"
5. A resposta serÃ¡ um nÃºmero representando a classe prevista, nesse caso o response body serÃ¡:

```json
{
  "prediction": 0
}
```

## InterpretaÃ§Ã£o da prediÃ§Ã£o

O modelo treinado com o dataset Iris retorna os seguintes cÃ³digos:

- 0: Setosa
- 1: Versicolor
- 2: Virginica

## Executar Testes

Com Docker

```bash
docker-compose run --rm test
```

## DependÃªncias principais

Contidas no arquivo `requirements.txt`:

```
fastapi==0.111.0
uvicorn==0.29.0
scikit-learn==1.4.2
joblib==1.4.2
numpy==1.26.4
pytest==8.2.1
```

## Contato
LÃ¡zara Camila  
lazaracamila@gmail.com